{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmkTve9Roz0r"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2911,
     "status": "ok",
     "timestamp": 1762135368327,
     "user": {
      "displayName": "Jiahao",
      "userId": "13321443423351605962"
     },
     "user_tz": -480
    },
    "id": "CXCiv-t6nR-l",
    "outputId": "40f140c1-2fab-47c0-c14d-49cea5cc051a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2804,
     "status": "ok",
     "timestamp": 1762135371133,
     "user": {
      "displayName": "Jiahao",
      "userId": "13321443423351605962"
     },
     "user_tz": -480
    },
    "id": "ZSywx7U9jg92"
   },
   "outputs": [],
   "source": [
    "!pip -q install \"tensorflow==2.19.0\" \"tensorflow-recommenders==0.7.3\" gdown pandas numpy scipy scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1626,
     "status": "ok",
     "timestamp": 1762135372757,
     "user": {
      "displayName": "Jiahao",
      "userId": "13321443423351605962"
     },
     "user_tz": -480
    },
    "id": "zMVGEvnKjpPn"
   },
   "outputs": [],
   "source": [
    "# ==== CONFIG (yours) ====\n",
    "CSV_PATH = \"../data/raw/transactions.csv\"  # change if needed\n",
    "USER_COL = \"customerID\"\n",
    "ITEM_COL = \"ISIN\"\n",
    "TS_COL   = \"timestamp\"       # prefer this; we'll fallback if not found\n",
    "TYPE_COL = \"transactionType\"\n",
    "VALUE_COL = \"totalValue\"     # optional weight\n",
    "USE_VALUE_WEIGHT = True\n",
    "INCLUDE_SELL = False\n",
    "K = 10\n",
    "MIN_USER_EVENTS = 2\n",
    "\n",
    "# ==== MOUNT DRIVE ====\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# ==== LOAD ====\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Some cleaned files use 'transaction_date' instead of 'timestamp'\n",
    "TS_COL_FINAL = TS_COL if TS_COL in df.columns else (\"transaction_date\" if \"transaction_date\" in df.columns else None)\n",
    "if TS_COL_FINAL is None:\n",
    "    raise ValueError(\"No timestamp column found. Expected 'timestamp' or 'transaction_date'.\")\n",
    "\n",
    "need = {USER_COL, ITEM_COL, TYPE_COL, TS_COL_FINAL}\n",
    "missing = need - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing required columns: {missing}\")\n",
    "\n",
    "# Keep useful optional columns if present (they'll be used in TFRS features)\n",
    "maybe_cols = [\n",
    "    VALUE_COL, \"customerType\",\"riskLevel\",\"investmentCapacity\",\"account_creation_date\",\n",
    "    \"assetName\",\"assetCategory\",\"assetSubCategory\",\"sector\",\"industry\",\n",
    "    \"country\",\"marketClass\",\"channel\",\"units\",\"exchangeID\",\"marketID\"\n",
    "]\n",
    "keep = list(need) + [c for c in maybe_cols if c in df.columns]\n",
    "df = df[keep].copy()\n",
    "\n",
    "# Parse dates\n",
    "df[TS_COL_FINAL] = pd.to_datetime(df[TS_COL_FINAL], errors=\"coerce\")\n",
    "if \"account_creation_date\" in df.columns:\n",
    "    df[\"account_creation_date\"] = pd.to_datetime(df[\"account_creation_date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[USER_COL, ITEM_COL, TS_COL_FINAL, TYPE_COL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 7387,
     "status": "ok",
     "timestamp": 1762135380145,
     "user": {
      "displayName": "Jiahao",
      "userId": "13321443423351605962"
     },
     "user_tz": -480
    },
    "id": "bQ6eJ6S-k_CY"
   },
   "outputs": [],
   "source": [
    "def event_weight(row):\n",
    "    t = str(row[TYPE_COL]).strip().lower()\n",
    "    if t == \"buy\":\n",
    "        if USE_VALUE_WEIGHT and (VALUE_COL in df.columns):\n",
    "            v = float(row.get(VALUE_COL, 1.0) or 1.0)\n",
    "            return np.log1p(max(v, 0.0))  # damp whales\n",
    "        return 1.0\n",
    "    if t == \"sell\":\n",
    "        return 0.1 if INCLUDE_SELL else 0.0\n",
    "    return 0.0\n",
    "\n",
    "df[\"weight\"] = df.apply(event_weight, axis=1)\n",
    "df = df[df[\"weight\"] > 0]\n",
    "\n",
    "# User must have at least 2 unique items for LLOO\n",
    "ucount = df.groupby(USER_COL)[ITEM_COL].nunique()\n",
    "df = df[df[USER_COL].isin(ucount[ucount >= MIN_USER_EVENTS].index)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3404,
     "status": "ok",
     "timestamp": 1762135383552,
     "user": {
      "displayName": "Jiahao",
      "userId": "13321443423351605962"
     },
     "user_tz": -480
    },
    "id": "jkuyadNRlCWw",
    "outputId": "27781d2e-1399-4be4-b9dd-55b0fa1e6138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users=14175, Items=303, Train rows=195983, Test users=14175\n"
     ]
    }
   ],
   "source": [
    "# Encode IDs\n",
    "uid2idx = {u:i for i,u in enumerate(df[USER_COL].astype(str).unique())}\n",
    "iid2idx = {i:j for j,i in enumerate(df[ITEM_COL].astype(str).unique())}\n",
    "df[\"u\"] = df[USER_COL].astype(str).map(uid2idx)\n",
    "df[\"i\"] = df[ITEM_COL].astype(str).map(iid2idx)\n",
    "\n",
    "# Sort by time and LLOO split\n",
    "df = df.sort_values([USER_COL, TS_COL_FINAL])\n",
    "last  = df.groupby(\"u\").tail(1)                 # test\n",
    "train = pd.concat([df, last]).drop_duplicates(keep=False)\n",
    "\n",
    "n_users, n_items = len(uid2idx), len(iid2idx)\n",
    "\n",
    "# Known items per user (for masking at inference)\n",
    "from collections import defaultdict\n",
    "known_items = defaultdict(set)\n",
    "for u, grp in train.groupby(\"u\"):\n",
    "    known_items[u] = set(grp[\"i\"].tolist())\n",
    "\n",
    "# Ground truth dict\n",
    "test_truth = last.groupby(\"u\")[\"i\"].apply(list).to_dict()\n",
    "\n",
    "print(f\"Users={n_users}, Items={n_items}, Train rows={len(train)}, Test users={len(test_truth)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1762135383557,
     "user": {
      "displayName": "Jiahao",
      "userId": "13321443423351605962"
     },
     "user_tz": -480
    },
    "id": "wt9h-Is6lGGz"
   },
   "outputs": [],
   "source": [
    "def hit_at_k(recs, truth):   return 1.0 if any(t in recs for t in truth) else 0.0\n",
    "def recall_at_k(recs, truth):return len(set(recs) & set(truth)) / len(truth)\n",
    "def ndcg_at_k(recs, truth):\n",
    "    dcg = 0.0\n",
    "    for r, i in enumerate(recs, start=1):\n",
    "        if i in truth: dcg += 1.0 / np.log2(r + 1)\n",
    "    idcg = sum(1.0 / np.log2(r + 1) for r in range(1, min(len(truth), len(recs)) + 1))\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def evaluate(recommender, name, K=K):\n",
    "    import numpy as np\n",
    "    HR, REC, NDCG = [], [], []\n",
    "    for u, truth in test_truth.items():\n",
    "        recs = recommender(u, K)\n",
    "        HR.append(hit_at_k(recs, truth))\n",
    "        REC.append(recall_at_k(recs, truth))\n",
    "        NDCG.append(ndcg_at_k(recs, truth))\n",
    "    print(f\"{name:14s} | HR@{K}: {np.mean(HR):.4f}  Recall@{K}: {np.mean(REC):.4f}  NDCG@{K}: {np.mean(NDCG):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27970,
     "status": "ok",
     "timestamp": 1762135411529,
     "user": {
      "displayName": "Jiahao",
      "userId": "13321443423351605962"
     },
     "user_tz": -480
    },
    "id": "KTzS3t7BlJxF",
    "outputId": "189f2554-0b89-432a-bf5d-3e130bdd4839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 311ms/step - loss: 32839.7500 - regularization_loss: 0.0000e+00 - total_loss: 32839.7500\n",
      "Epoch 2/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 30981.7168 - regularization_loss: 0.0000e+00 - total_loss: 30981.7168\n",
      "Epoch 3/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 29351.4141 - regularization_loss: 0.0000e+00 - total_loss: 29351.4141\n",
      "Epoch 4/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 28098.2246 - regularization_loss: 0.0000e+00 - total_loss: 28098.2246\n",
      "Epoch 5/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 27239.1484 - regularization_loss: 0.0000e+00 - total_loss: 27239.1484\n",
      "TFRS TwoTower  | HR@10: 0.3557  Recall@10: 0.3557  NDCG@10: 0.2402\n"
     ]
    }
   ],
   "source": [
    "# ===== 5) TFRS Two-Tower (IDs only) — training w/o FactorizedTopK, eval w/ your metrics =====\n",
    "import numpy as np\n",
    "import tensorflow as tf, tensorflow_recommenders as tfrs\n",
    "from tensorflow import keras\n",
    "\n",
    "# 5.1 Build tf.data from your train pairs (IDs only). These are the positive interactions\n",
    "train_pos = train[[\"u\",\"i\"]].drop_duplicates()\n",
    "train_ds = tf.data.Dataset.from_tensor_slices({\n",
    "    \"user_id\": train_pos[\"u\"].values.astype(np.int32),\n",
    "    \"item_id\": train_pos[\"i\"].values.astype(np.int32),\n",
    "}).shuffle(1_000_000, seed=42).batch(4096).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# 5.2 Define towers explicitly (hard-cast shapes to ints). These are user-related inputs and item-properties inputs.\n",
    "n_users = int(n_users); n_items = int(n_items); EMB = 64\n",
    "\n",
    "user_in  = keras.Input(shape=(), dtype=tf.int32, name=\"user_id\")\n",
    "item_in  = keras.Input(shape=(), dtype=tf.int32, name=\"item_id\")\n",
    "user_vec = keras.layers.Embedding(input_dim=n_users, output_dim=EMB, name=\"user_emb\")(user_in)\n",
    "item_vec = keras.layers.Embedding(input_dim=n_items, output_dim=EMB, name=\"item_emb\")(item_in)\n",
    "\n",
    "user_model = keras.Model(inputs=user_in, outputs=user_vec, name=\"user_tower\")\n",
    "item_model = keras.Model(inputs=item_in, outputs=item_vec, name=\"item_tower\")\n",
    "\n",
    "class TwoTower(tfrs.models.Model):\n",
    "    def __init__(self, user_model, item_model):\n",
    "        super().__init__()\n",
    "        self.user_model = user_model\n",
    "        self.item_model = item_model\n",
    "        # Use Retrieval loss, but skip built-in TopK metric to avoid the Keras bug.\n",
    "        self.task = tfrs.tasks.Retrieval()\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        u = self.user_model(features[\"user_id\"])\n",
    "        i = self.item_model(features[\"item_id\"])\n",
    "        return self.task(u, i)\n",
    "\n",
    "model = TwoTower(user_model, item_model)\n",
    "model.compile(optimizer=keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "# 5.3 Train\n",
    "history = model.fit(train_ds, epochs=5, verbose=1)\n",
    "\n",
    "# 5.4 Precompute embeddings\n",
    "item_ids   = tf.range(n_items, dtype=tf.int32)\n",
    "item_embs  = item_model(item_ids)             # (n_items, EMB)\n",
    "item_embsT = tf.transpose(item_embs)\n",
    "\n",
    "user_ids   = tf.range(n_users, dtype=tf.int32)\n",
    "user_embs  = user_model(user_ids)             # (n_users, EMB)\n",
    "\n",
    "# 5.5 Recommend + evaluate with your metrics\n",
    "def rec_tfrs(u, k=K):\n",
    "    # Get user vector as shape (EMB,)\n",
    "    ue = tf.gather(user_embs, u)          # (EMB,) or (1,EMB)\n",
    "    ue = tf.reshape(ue, [-1])             # force (EMB,)\n",
    "\n",
    "    # Score = item_embs @ ue  -> (n_items,)\n",
    "    # item_embs has shape (n_items, EMB)\n",
    "    scores = tf.linalg.matvec(item_embs, ue).numpy()\n",
    "\n",
    "    # Mask items the user already interacted with in TRAIN\n",
    "    for i in known_items.get(u, []):\n",
    "        scores[i] = -np.inf\n",
    "\n",
    "    k_eff = min(k, max(1, scores.size - 1))\n",
    "    top = np.argpartition(-scores, k_eff-1)[:k_eff]\n",
    "    return list(top[np.argsort(-scores[top])][:k])\n",
    "\n",
    "\n",
    "evaluate(rec_tfrs, \"TFRS TwoTower\", K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13525,
     "status": "ok",
     "timestamp": 1762135425050,
     "user": {
      "displayName": "Jiahao",
      "userId": "13321443423351605962"
     },
     "user_tz": -480
    },
    "id": "2Ibd-S8TlN8L",
    "outputId": "5c61be43-bcd8-4af5-c7ef-9babbb2accd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFRS TwoTower  | HR@10: 0.3557  Recall@10: 0.3557  NDCG@10: 0.2402\n"
     ]
    }
   ],
   "source": [
    "# ===== 6) Recommend with TFRS + evaluate (fixed matvec shapes) =====\n",
    "\n",
    "# Precompute embeddings\n",
    "item_ids   = tf.range(n_items, dtype=tf.int32)\n",
    "item_embs  = item_model(item_ids)             # (n_items, EMB)\n",
    "user_ids   = tf.range(n_users, dtype=tf.int32)\n",
    "user_embs  = user_model(user_ids)             # (n_users, EMB)\n",
    "\n",
    "def rec_tfrs(u, k=K):\n",
    "    # user vector: (EMB,)\n",
    "    ue = tf.reshape(tf.gather(user_embs, u), [-1])\n",
    "    # scores: (n_items,) = item_embs @ ue\n",
    "    scores = tf.linalg.matvec(item_embs, ue).numpy()\n",
    "\n",
    "    # mask train-known items for this user\n",
    "    for i in known_items.get(u, []):\n",
    "        scores[i] = -np.inf\n",
    "\n",
    "    k_eff = min(k, max(1, scores.size - 1))\n",
    "    top = np.argpartition(-scores, k_eff-1)[:k_eff]\n",
    "    return list(top[np.argsort(-scores[top])][:k])\n",
    "\n",
    "evaluate(rec_tfrs, \"TFRS TwoTower\", K)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
