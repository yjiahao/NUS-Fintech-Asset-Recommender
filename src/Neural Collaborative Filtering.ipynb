{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ix5fpW6RVH8J"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21209,
     "status": "ok",
     "timestamp": 1761280934218,
     "user": {
      "displayName": "Arshelle Raheja",
      "userId": "10851582231821550198"
     },
     "user_tz": -480
    },
    "id": "kJRVagifVi8R",
    "outputId": "a7ced2fa-ec11-422f-e511-d5fce956f2b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "executionInfo": {
     "elapsed": 17464,
     "status": "ok",
     "timestamp": 1761280951680,
     "user": {
      "displayName": "Arshelle Raheja",
      "userId": "10851582231821550198"
     },
     "user_tz": -480
    },
    "id": "2aU0WYGoVtlT",
    "outputId": "5f3d082d-9d9e-4c75-a164-25157f35ab3d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-63282cb8-34ee-404e-b3b1-9c14bd8f85b3\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>customerType</th>\n",
       "      <th>riskLevel</th>\n",
       "      <th>investmentCapacity</th>\n",
       "      <th>account_creation_date</th>\n",
       "      <th>ISIN</th>\n",
       "      <th>transactionID</th>\n",
       "      <th>transactionType</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>totalValue</th>\n",
       "      <th>...</th>\n",
       "      <th>days_since_last_trade</th>\n",
       "      <th>holding_duration_days</th>\n",
       "      <th>cust_asset_total_value</th>\n",
       "      <th>cust_asset_n_txn</th>\n",
       "      <th>cust_asset_avg_value</th>\n",
       "      <th>cust_asset_buy_ratio</th>\n",
       "      <th>last_cust_asset_txn</th>\n",
       "      <th>cust_asset_days_since_last_txn</th>\n",
       "      <th>cust_total_value</th>\n",
       "      <th>cust_asset_portfolio_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00017496858921195E5A</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Aggressive</td>\n",
       "      <td>CAP_GT300K</td>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>GRS434003000</td>\n",
       "      <td>7590224</td>\n",
       "      <td>Buy</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1793</td>\n",
       "      <td>229180.0</td>\n",
       "      <td>12</td>\n",
       "      <td>19098.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-05-19</td>\n",
       "      <td>560</td>\n",
       "      <td>728451.013</td>\n",
       "      <td>0.314613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00017496858921195E5A</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Aggressive</td>\n",
       "      <td>CAP_GT300K</td>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>GRS434003000</td>\n",
       "      <td>7607029</td>\n",
       "      <td>Sell</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>12080.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1793</td>\n",
       "      <td>229180.0</td>\n",
       "      <td>12</td>\n",
       "      <td>19098.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-05-19</td>\n",
       "      <td>560</td>\n",
       "      <td>728451.013</td>\n",
       "      <td>0.314613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00017496858921195E5A</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Aggressive</td>\n",
       "      <td>CAP_GT300K</td>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>GRS434003000</td>\n",
       "      <td>7634872</td>\n",
       "      <td>Buy</td>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>13400.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1793</td>\n",
       "      <td>229180.0</td>\n",
       "      <td>12</td>\n",
       "      <td>19098.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-05-19</td>\n",
       "      <td>560</td>\n",
       "      <td>728451.013</td>\n",
       "      <td>0.314613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017496858921195E5A</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Aggressive</td>\n",
       "      <td>CAP_GT300K</td>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>GRS434003000</td>\n",
       "      <td>7652627</td>\n",
       "      <td>Sell</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>12700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1793</td>\n",
       "      <td>229180.0</td>\n",
       "      <td>12</td>\n",
       "      <td>19098.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-05-19</td>\n",
       "      <td>560</td>\n",
       "      <td>728451.013</td>\n",
       "      <td>0.314613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017496858921195E5A</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Aggressive</td>\n",
       "      <td>CAP_GT300K</td>\n",
       "      <td>2021-03-19</td>\n",
       "      <td>GRS434003000</td>\n",
       "      <td>7664807</td>\n",
       "      <td>Buy</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>12150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1793</td>\n",
       "      <td>229180.0</td>\n",
       "      <td>12</td>\n",
       "      <td>19098.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2021-05-19</td>\n",
       "      <td>560</td>\n",
       "      <td>728451.013</td>\n",
       "      <td>0.314613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63282cb8-34ee-404e-b3b1-9c14bd8f85b3')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-63282cb8-34ee-404e-b3b1-9c14bd8f85b3 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-63282cb8-34ee-404e-b3b1-9c14bd8f85b3');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-f21ab327-99e7-4790-a030-78d4c956fde1\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f21ab327-99e7-4790-a030-78d4c956fde1')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-f21ab327-99e7-4790-a030-78d4c956fde1 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "             customerID  customerType   riskLevel investmentCapacity  \\\n",
       "0  00017496858921195E5A  Professional  Aggressive         CAP_GT300K   \n",
       "1  00017496858921195E5A  Professional  Aggressive         CAP_GT300K   \n",
       "2  00017496858921195E5A  Professional  Aggressive         CAP_GT300K   \n",
       "3  00017496858921195E5A  Professional  Aggressive         CAP_GT300K   \n",
       "4  00017496858921195E5A  Professional  Aggressive         CAP_GT300K   \n",
       "\n",
       "  account_creation_date          ISIN  transactionID transactionType  \\\n",
       "0            2021-03-19  GRS434003000        7590224             Buy   \n",
       "1            2021-03-19  GRS434003000        7607029            Sell   \n",
       "2            2021-03-19  GRS434003000        7634872             Buy   \n",
       "3            2021-03-19  GRS434003000        7652627            Sell   \n",
       "4            2021-03-19  GRS434003000        7664807             Buy   \n",
       "\n",
       "  transaction_date  totalValue  ...  days_since_last_trade  \\\n",
       "0       2020-03-27     11000.0  ...                      0   \n",
       "1       2020-04-06     12080.0  ...                      0   \n",
       "2       2020-04-24     13400.0  ...                      0   \n",
       "3       2020-05-07     12700.0  ...                      0   \n",
       "4       2020-05-15     12150.0  ...                      0   \n",
       "\n",
       "  holding_duration_days cust_asset_total_value cust_asset_n_txn  \\\n",
       "0                  1793               229180.0               12   \n",
       "1                  1793               229180.0               12   \n",
       "2                  1793               229180.0               12   \n",
       "3                  1793               229180.0               12   \n",
       "4                  1793               229180.0               12   \n",
       "\n",
       "  cust_asset_avg_value cust_asset_buy_ratio last_cust_asset_txn  \\\n",
       "0         19098.333333                  0.5          2021-05-19   \n",
       "1         19098.333333                  0.5          2021-05-19   \n",
       "2         19098.333333                  0.5          2021-05-19   \n",
       "3         19098.333333                  0.5          2021-05-19   \n",
       "4         19098.333333                  0.5          2021-05-19   \n",
       "\n",
       "  cust_asset_days_since_last_txn cust_total_value cust_asset_portfolio_share  \n",
       "0                            560       728451.013                   0.314613  \n",
       "1                            560       728451.013                   0.314613  \n",
       "2                            560       728451.013                   0.314613  \n",
       "3                            560       728451.013                   0.314613  \n",
       "4                            560       728451.013                   0.314613  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = '../data/processed/engineered_features.csv'\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1761280951681,
     "user": {
      "displayName": "Arshelle Raheja",
      "userId": "10851582231821550198"
     },
     "user_tz": -480
    },
    "id": "Chw0mOVpWOhX",
    "outputId": "f66d9ee4-82c4-4faf-e004-6e3a5623d1be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customerID', 'customerType', 'riskLevel', 'investmentCapacity',\n",
       "       'account_creation_date', 'ISIN', 'transactionID', 'transactionType',\n",
       "       'transaction_date', 'totalValue', 'units', 'channel', 'marketID',\n",
       "       'assetName', 'assetCategory', 'assetSubCategory', 'sector', 'industry',\n",
       "       'asset_description', 'exchangeID', 'name', 'market_description',\n",
       "       'country', 'tradingHours', 'marketClass', 'days_since_txn',\n",
       "       'value_per_unit', 'is_buy', 'is_sell', 'channel_encoded',\n",
       "       'account_age_days', 'risk_encoded', 'capacity_numeric',\n",
       "       'n_unique_assets', 'n_unique_sectors', 'n_unique_markets',\n",
       "       'total_invested', 'avg_txn_value', 'median_units', 'n_transactions_x',\n",
       "       'n_buys_x', 'n_sells_x', 'buy_ratio_x', 'channel_pref', 'last_txn_date',\n",
       "       'days_since_last_txn', 'risk_level', 'invest_capacity',\n",
       "       'portfolio_concentration', 'day_of_week', 'month', 'quarter',\n",
       "       'n_unique_investors', 'total_traded_value', 'avg_traded_value',\n",
       "       'n_transactions_y', 'n_buys_y', 'n_sells_y', 'buy_ratio_y',\n",
       "       'last_trade_date', 'days_since_last_trade', 'holding_duration_days',\n",
       "       'cust_asset_total_value', 'cust_asset_n_txn', 'cust_asset_avg_value',\n",
       "       'cust_asset_buy_ratio', 'last_cust_asset_txn',\n",
       "       'cust_asset_days_since_last_txn', 'cust_total_value',\n",
       "       'cust_asset_portfolio_share'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCsbUAxMWVF7"
   },
   "outputs": [],
   "source": [
    "df_pos = df[df[\"is_buy\"]==1].copy()\n",
    "df_pos[\"user_id\"] = df_pos[\"customerID\"]\n",
    "df_pos[\"item_id\"] = df_pos[\"ISIN\"]\n",
    "ts = pd.to_datetime(df_pos[\"transaction_date\"], errors=\"coerce\")\n",
    "df_pos = df_pos[ts.notna()].copy()\n",
    "df_pos[\"timestamp\"] = ts[ts.notna()].astype(\"int64\") // 10**9\n",
    "df_pos[\"rating\"] = 1\n",
    "df_pos = df_pos[[\"user_id\", \"item_id\", \"timestamp\", \"rating\"]].sort_values(\"timestamp\")\n",
    "df_pos = df_pos.drop_duplicates([\"user_id\", \"item_id\"], keep=\"last\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3M-YzujX5kq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rI2lePkTbw2_"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1761280956073,
     "user": {
      "displayName": "Arshelle Raheja",
      "userId": "10851582231821550198"
     },
     "user_tz": -480
    },
    "id": "eOf-0WUlcC3O",
    "outputId": "1f9d3a08-4087-4287-8bbc-48515729b7d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIHIYirUcD7g"
   },
   "outputs": [],
   "source": [
    "EMBED_GMF = 32\n",
    "EMBED_MLP = 32\n",
    "MLP_LAYERS = (128, 64, 32)\n",
    "NEG_PER_POS = 4\n",
    "BATCH_SIZE = 2048\n",
    "EPOCHS = 10\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-6\n",
    "TOPK = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAP_RSmNcTF5"
   },
   "outputs": [],
   "source": [
    "df_cf = df_pos[df_pos[\"rating\"]>0].copy()\n",
    "test_df = df_cf.groupby(\"user_id\").tail(1)\n",
    "train_df = df_cf.drop(test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89,
     "status": "ok",
     "timestamp": 1761280956229,
     "user": {
      "displayName": "Arshelle Raheja",
      "userId": "10851582231821550198"
     },
     "user_tz": -480
    },
    "id": "8ZMinfGqctm4",
    "outputId": "2df151a9-ff66-4496-9331-05a6773e1f7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3811300264.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"u\"] = test_df[\"user_id\"].map(user2id).astype(int)\n",
      "/tmp/ipython-input-3811300264.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"i\"] = test_df[\"item_id\"].map(item2id).astype(int)\n"
     ]
    }
   ],
   "source": [
    "user_all = pd.concat([train_df[\"user_id\"], test_df[\"user_id\"]])\n",
    "item_all = pd.concat([train_df[\"item_id\"], test_df[\"item_id\"]])\n",
    "user2id = {u: i for i, u in enumerate(user_all.astype(\"category\").cat.categories)}\n",
    "item2id = {i: j for j, i in enumerate(item_all.astype(\"category\").cat.categories)}\n",
    "train_df[\"u\"] = train_df[\"user_id\"].map(user2id).astype(int)\n",
    "train_df[\"i\"] = train_df[\"item_id\"].map(item2id).astype(int)\n",
    "test_df[\"u\"] = test_df[\"user_id\"].map(user2id).astype(int)\n",
    "test_df[\"i\"] = test_df[\"item_id\"].map(item2id).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1761280956243,
     "user": {
      "displayName": "Arshelle Raheja",
      "userId": "10851582231821550198"
     },
     "user_tz": -480
    },
    "id": "MGNsw4GmkBEv",
    "outputId": "64836d7a-e68e-40f3-c487-5e76edf7772b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29090 320\n"
     ]
    }
   ],
   "source": [
    "n_users = len(user2id)\n",
    "n_items = len(item2id)\n",
    "print(n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cua0BO02kfRt"
   },
   "outputs": [],
   "source": [
    "user_pos = defaultdict(set)\n",
    "for u,i in zip(train_df.u.values, train_df.i.values):\n",
    "    user_pos[int(u)].add(int(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4JBxlyEksBC"
   },
   "outputs": [],
   "source": [
    "class PairwiseImplicitDataset(Dataset):\n",
    "    def __init__(self, df, n_items, user_pos, neg_per_pos=4):\n",
    "        import numpy as np\n",
    "        self.user_features = [\"risk_encoded\", \"capacity_numeric\", \"channel_encoded\", \"account_age_days\"]\n",
    "        self.item_features = [\"assetCategory\", \"sector\", \"industry\", \"marketClass\"]\n",
    "\n",
    "        missing_user = [c for c in self.user_features if c not in df.columns]\n",
    "        missing_item = [c for c in self.item_features if c not in df.columns]\n",
    "        for c in [\"u\", \"i\"]:\n",
    "            if c not in df.columns:\n",
    "                missing_user.append(c)\n",
    "        if missing_user or missing_item:\n",
    "            raise ValueError(f\"Missing columns. user: {missing_user}, item: {missing_item}\")\n",
    "\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        self.users = df[\"u\"].to_numpy(dtype=np.int64)\n",
    "        self.items = df[\"i\"].to_numpy(dtype=np.int64)\n",
    "        self.uf_mat = df[self.user_features].to_numpy(dtype=np.float32)\n",
    "        self.if_mat = df[self.item_features].to_numpy(dtype=np.float32)\n",
    "\n",
    "        self.n_items = int(n_items)\n",
    "        self.user_pos = user_pos\n",
    "        self.neg_per_pos = int(neg_per_pos)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.users.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        import numpy as np\n",
    "        u = int(self.users[idx])\n",
    "        p = int(self.items[idx])\n",
    "        uf = self.uf_mat[idx]\n",
    "        ifeat = self.if_mat[idx]\n",
    "\n",
    "        # negative sampling\n",
    "        liked = self.user_pos.get(u, set())\n",
    "        negs = []\n",
    "        if len(liked) < self.n_items - 1:\n",
    "            comp = np.setdiff1d(\n",
    "                np.arange(self.n_items, dtype=np.int64),\n",
    "                np.fromiter(liked, dtype=np.int64, count=len(liked)),\n",
    "                assume_unique=False\n",
    "            )\n",
    "            comp = comp[comp != p]\n",
    "            if comp.size >= self.neg_per_pos:\n",
    "                negs = np.random.choice(comp, size=self.neg_per_pos, replace=False).astype(np.int64)\n",
    "            else:\n",
    "                negs = np.random.choice(comp, size=self.neg_per_pos, replace=True).astype(np.int64)\n",
    "        else:\n",
    "            while len(negs) < self.neg_per_pos:\n",
    "                j = np.random.randint(0, self.n_items, dtype=np.int64)\n",
    "                if j != p and j not in liked:\n",
    "                    negs.append(j)\n",
    "            negs = np.asarray(negs, dtype=np.int64)\n",
    "\n",
    "        return (\n",
    "            torch.as_tensor(u, dtype=torch.long),\n",
    "            torch.as_tensor(p, dtype=torch.long),\n",
    "            torch.as_tensor(negs, dtype=torch.long),\n",
    "            torch.from_numpy(uf),\n",
    "            torch.from_numpy(ifeat),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1761281564477,
     "user": {
      "displayName": "Arshelle Raheja",
      "userId": "10851582231821550198"
     },
     "user_tz": -480
    },
    "id": "EUt0UTlhjXI1",
    "outputId": "a0e3c324-1dbf-4990-9218-1ac922310e10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'item_id', 'timestamp', 'rating', 'u', 'i']\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1761281568361,
     "user": {
      "displayName": "Arshelle Raheja",
      "userId": "10851582231821550198"
     },
     "user_tz": -480
    },
    "id": "LX3a0SFgkurl",
    "outputId": "7f993419-3dd3-4120-820c-7dad8483590a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2650109063.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.5 1.  0.5 ... 0.  0.  0. ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  user_base.loc[mask_train, user_features] = scaler.fit_transform(\n",
      "/tmp/ipython-input-2650109063.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.16908898 0.2112726  0.2112726  ... 0.2112726  0.2112726  0.28571429]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  user_base.loc[mask_train, user_features] = scaler.fit_transform(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature merge complete.\n"
     ]
    }
   ],
   "source": [
    "# Feature Prep + Safe Merges (drop-in replacement)\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# 1) Declare feature columns\n",
    "user_features = [\"risk_encoded\", \"capacity_numeric\", \"channel_encoded\", \"account_age_days\"]\n",
    "item_features = [\"assetCategory\", \"sector\", \"industry\", \"marketClass\"]\n",
    "\n",
    "# 2) Work on a copy of the master table to avoid side effects\n",
    "df_enc = df.copy()\n",
    "\n",
    "# 3) Encode item categorical columns if needed (no-op for numeric)\n",
    "for col in item_features:\n",
    "    if df_enc[col].dtype == \"object\":\n",
    "        le = LabelEncoder()\n",
    "        df_enc[col] = le.fit_transform(df_enc[col].astype(str))\n",
    "\n",
    "# 4) Build per-user table and scale user features WITHOUT leakage\n",
    "user_base = df_enc.drop_duplicates(\"customerID\")[[\"customerID\"] + user_features].copy()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit on users present in train_df, then transform all users\n",
    "train_users = train_df[\"user_id\"].unique()\n",
    "mask_train = user_base[\"customerID\"].isin(train_users)\n",
    "\n",
    "user_base.loc[mask_train, user_features] = scaler.fit_transform(\n",
    "    user_base.loc[mask_train, user_features]\n",
    ")\n",
    "if (~mask_train).any():\n",
    "    user_base.loc[~mask_train, user_features] = scaler.transform(\n",
    "        user_base.loc[~mask_train, user_features]\n",
    "    )\n",
    "\n",
    "# 5) Build per-item table (already numerically encoded above)\n",
    "item_base = df_enc.drop_duplicates(\"ISIN\")[[\"ISIN\"] + item_features].copy()\n",
    "\n",
    "# 6) Clean old columns (prevents _x/_y suffix conflicts on reruns)\n",
    "train_df = train_df.drop(columns=user_features + item_features, errors=\"ignore\").copy()\n",
    "test_df  = test_df.drop(columns=user_features + item_features, errors=\"ignore\").copy()\n",
    "\n",
    "# 7) Merge user + item features into train/test\n",
    "train_df = train_df.merge(user_base, left_on=\"user_id\", right_on=\"customerID\", how=\"left\")\n",
    "train_df = train_df.merge(item_base, left_on=\"item_id\", right_on=\"ISIN\", how=\"left\")\n",
    "train_df.drop(columns=[\"customerID\", \"ISIN\"], inplace=True, errors=\"ignore\")\n",
    "train_df[user_features + item_features] = (\n",
    "    train_df[user_features + item_features].fillna(0).astype(\"float32\")\n",
    ")\n",
    "\n",
    "test_df = test_df.merge(user_base, left_on=\"user_id\", right_on=\"customerID\", how=\"left\")\n",
    "test_df = test_df.merge(item_base, left_on=\"item_id\", right_on=\"ISIN\", how=\"left\")\n",
    "test_df.drop(columns=[\"customerID\", \"ISIN\"], inplace=True, errors=\"ignore\")\n",
    "test_df[user_features + item_features] = (\n",
    "    test_df[user_features + item_features].fillna(0).astype(\"float32\")\n",
    ")\n",
    "\n",
    "# 8) Sanity checks\n",
    "assert set(user_features) <= set(train_df.columns), \"User features missing in train_df\"\n",
    "assert set(item_features) <= set(train_df.columns), \"Item features missing in train_df\"\n",
    "assert set(user_features) <= set(test_df.columns),  \"User features missing in test_df\"\n",
    "assert set(item_features) <= set(test_df.columns),  \"Item features missing in test_df\"\n",
    "\n",
    "print(\"Feature merge complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0u45OZv2kQj0"
   },
   "outputs": [],
   "source": [
    "# make sure these exist: train_df, n_items, user_pos, NEG_PER_POS, BATCH_SIZE\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    PairwiseImplicitDataset(train_df, n_items, user_pos, NEG_PER_POS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ShlCr9Lkwwo"
   },
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, eg=32, em=32, layers=(128,64,32)):\n",
    "        super().__init__()\n",
    "        # GMF branch\n",
    "        self.user_gmf = nn.Embedding(n_users, eg)\n",
    "        self.item_gmf = nn.Embedding(n_items, eg)\n",
    "        # MLP branch\n",
    "        self.user_mlp = nn.Embedding(n_users, em)\n",
    "        self.item_mlp = nn.Embedding(n_items, em)\n",
    "        dim = em*2\n",
    "        mlp = []\n",
    "        for h in layers:\n",
    "            mlp += [nn.Linear(dim, h), nn.ReLU()]\n",
    "            dim = h\n",
    "        self.mlp = nn.Sequential(*mlp)\n",
    "        # fusion\n",
    "        self.out = nn.Linear(eg + layers[-1], 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self._init()\n",
    "    def _init(self):\n",
    "        for emb in [self.user_gmf, self.item_gmf, self.user_mlp, self.item_mlp]:\n",
    "            nn.init.normal_(emb.weight, std=0.01)\n",
    "        for m in self.mlp:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight); nn.init.zeros_(m.bias)\n",
    "        nn.init.xavier_uniform_(self.out.weight); nn.init.zeros_(self.out.bias)\n",
    "    def forward(self, u, i, uf=None, ifeat=None):\n",
    "      g = self.user_gmf(u) * self.item_gmf(i)\n",
    "      m = self.mlp(torch.cat([self.user_mlp(u), self.item_mlp(i)], dim=-1))\n",
    "\n",
    "      if uf is not None and ifeat is not None:\n",
    "          x = torch.cat([g, m, uf, ifeat], dim=-1)\n",
    "          out = self.out_ext(x)\n",
    "      else:\n",
    "          out = self.out(torch.cat([g, m], dim=-1))\n",
    "\n",
    "      return self.sig(out.squeeze(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rzEK0msrk2cP"
   },
   "outputs": [],
   "source": [
    "def bce_pos_neg(model, users, pos_items, neg_items):\n",
    "    B, K = neg_items.shape\n",
    "    users = users.to(DEVICE); pos_items = pos_items.to(DEVICE); neg_items = neg_items.to(DEVICE)\n",
    "    pos_scores = model(users, pos_items)\n",
    "    users_rep = users.unsqueeze(1).expand(-1, K).reshape(-1)\n",
    "    neg_scores = model(users_rep, neg_items.reshape(-1)).view(B, K)\n",
    "    loss = nn.functional.binary_cross_entropy(pos_scores, torch.ones_like(pos_scores))\n",
    "    loss += nn.functional.binary_cross_entropy(neg_scores, torch.zeros_like(neg_scores))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_biXAC7Hk4o5"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, test_df, user_pos, n_items, k=10, n_neg=99):\n",
    "    model.eval()\n",
    "    HR, NDCG = [], []\n",
    "    for u, pos in zip(test_df.u.values, test_df.i.values):\n",
    "        u = int(u); pos = int(pos)\n",
    "        negs = []\n",
    "        s = user_pos[u]\n",
    "        while len(negs) < n_neg:\n",
    "            j = np.random.randint(0, n_items)\n",
    "            if j != pos and j not in s:\n",
    "                negs.append(j)\n",
    "        items = np.array([pos] + negs, dtype=np.int64)\n",
    "        users = np.full_like(items, u)\n",
    "        scores = model(\n",
    "            torch.tensor(users, device=DEVICE),\n",
    "            torch.tensor(items, device=DEVICE)\n",
    "        ).cpu().numpy()\n",
    "        rank = scores.argsort()[::-1]\n",
    "        topk = items[rank[:k]]\n",
    "        HR.append(1 if pos in topk else 0)\n",
    "        if pos in topk:\n",
    "            idx = np.where(topk == pos)[0][0]\n",
    "            NDCG.append(1 / np.log2(idx + 2))\n",
    "        else:\n",
    "            NDCG.append(0.0)\n",
    "    return float(np.mean(HR)), float(np.mean(NDCG))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 404328,
     "status": "ok",
     "timestamp": 1761281980987,
     "user": {
      "displayName": "Arshelle Raheja",
      "userId": "10851582231821550198"
     },
     "user_tz": -480
    },
    "id": "peqyzabBk6_T",
    "outputId": "cd784592-a757-4672-a9a4-1dc2d5944f18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_bce=1.2890 | HR@10=0.601 | NDCG@10=0.294\n",
      "Epoch 02 | train_bce=0.8442 | HR@10=0.636 | NDCG@10=0.393\n",
      "Epoch 03 | train_bce=0.7430 | HR@10=0.632 | NDCG@10=0.399\n",
      "Epoch 04 | train_bce=0.7044 | HR@10=0.641 | NDCG@10=0.405\n",
      "Epoch 05 | train_bce=0.6746 | HR@10=0.672 | NDCG@10=0.417\n",
      "Epoch 06 | train_bce=0.6526 | HR@10=0.694 | NDCG@10=0.426\n",
      "Epoch 07 | train_bce=0.6243 | HR@10=0.693 | NDCG@10=0.426\n",
      "Epoch 08 | train_bce=0.6004 | HR@10=0.693 | NDCG@10=0.429\n",
      "Epoch 09 | train_bce=0.5705 | HR@10=0.705 | NDCG@10=0.433\n",
      "Epoch 10 | train_bce=0.5387 | HR@10=0.729 | NDCG@10=0.455\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = NeuMF(n_users, n_items, EMBED_GMF, EMBED_MLP, MLP_LAYERS).to(DEVICE)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "for e in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "\n",
    "    for u, p, n, _, _ in train_loader:\n",
    "        u = u.long().to(DEVICE)\n",
    "        p = p.long().to(DEVICE)\n",
    "        n = n.long().to(DEVICE)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss = bce_pos_neg(model, u, p, n)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        total += loss.item() * len(u)\n",
    "\n",
    "    # Evaluate after each epoch (features not used by model)\n",
    "    hr, ndcg = evaluate(model, test_df, user_pos, n_items, k=TOPK)\n",
    "\n",
    "    print(f\"Epoch {e:02d} | train_bce={total/len(train_df):.4f} | \"\n",
    "          f\"HR@{TOPK}={hr:.3f} | NDCG@{TOPK}={ndcg:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 535,
     "status": "ok",
     "timestamp": 1761282113265,
     "user": {
      "displayName": "Arshelle Raheja",
      "userId": "10851582231821550198"
     },
     "user_tz": -480
    },
    "id": "-NhXpZyDk9oV",
    "outputId": "8d6fe0de-b02f-48d4-fe8f-b6ad5fd3ef43"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2856375123.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.5 1.  0.5 ... 0.  0.  0. ]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  user_base.loc[mask_train_users, user_features] = scaler.fit_transform(\n",
      "/tmp/ipython-input-2856375123.py:26: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.16908898 0.2112726  0.2112726  ... 0.2112726  0.2112726  0.28571429]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  user_base.loc[mask_train_users, user_features] = scaler.fit_transform(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_features = [\"risk_encoded\", \"capacity_numeric\", \"channel_encoded\", \"account_age_days\"]\n",
    "item_features = [\"assetCategory\", \"sector\", \"industry\", \"marketClass\"]\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "df_enc = df.copy()  # avoid mutating original df\n",
    "\n",
    "\n",
    "labelers = {}\n",
    "for col in item_features:\n",
    "    if df_enc[col].dtype == \"object\":\n",
    "        le = LabelEncoder()\n",
    "        df_enc[col] = le.fit_transform(df_enc[col].astype(str))\n",
    "        labelers[col] = le\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Build per-user table first from FULL df_enc (raw), then fit on train users only\n",
    "user_base = df_enc.drop_duplicates(\"customerID\")[[\"customerID\"] + user_features].copy()\n",
    "\n",
    "train_users = train_df[\"user_id\"].unique()\n",
    "mask_train_users = user_base[\"customerID\"].isin(train_users)\n",
    "\n",
    "# Fit on train users only, then transform all users for consistency\n",
    "user_base.loc[mask_train_users, user_features] = scaler.fit_transform(\n",
    "    user_base.loc[mask_train_users, user_features]\n",
    ")\n",
    "user_base.loc[~mask_train_users, user_features] = scaler.transform(\n",
    "    user_base.loc[~mask_train_users, user_features]\n",
    ")\n",
    "\n",
    "\n",
    "item_base = df_enc.drop_duplicates(\"ISIN\")[[\"ISIN\"] + item_features].copy()\n",
    "\n",
    "\n",
    "train_df = train_df.drop(columns=user_features + item_features, errors=\"ignore\").copy()\n",
    "test_df  = test_df.drop(columns=user_features + item_features, errors=\"ignore\").copy()\n",
    "\n",
    "train_df = train_df.merge(user_base, left_on=\"user_id\", right_on=\"customerID\", how=\"left\")\n",
    "train_df = train_df.merge(item_base, left_on=\"item_id\", right_on=\"ISIN\", how=\"left\")\n",
    "train_df.drop(columns=[\"customerID\", \"ISIN\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "test_df = test_df.merge(user_base, left_on=\"user_id\", right_on=\"customerID\", how=\"left\")\n",
    "test_df = test_df.merge(item_base, left_on=\"item_id\", right_on=\"ISIN\", how=\"left\")\n",
    "test_df.drop(columns=[\"customerID\", \"ISIN\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "\n",
    "train_df[user_features + item_features] = train_df[user_features + item_features].fillna(0).astype(\"float32\")\n",
    "test_df[user_features + item_features]  = test_df[user_features + item_features].fillna(0).astype(\"float32\")\n",
    "\n",
    "# Sanity checks\n",
    "assert set(user_features) <= set(train_df.columns)\n",
    "assert set(item_features) <= set(train_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69Sz_5bmCZuc"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class ContextualImplicitDataset(Dataset):\n",
    "    def __init__(self, df, n_items, user_pos, neg_per_pos=4, max_tries=1000):\n",
    "        # Ensure row order is consistent\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # Integer ids for embeddings\n",
    "        self.users = df[\"u\"].to_numpy(dtype=np.int64)\n",
    "        self.items = df[\"i\"].to_numpy(dtype=np.int64)\n",
    "\n",
    "        # Context features (float32)\n",
    "        self.user_feats = df[user_features].to_numpy(dtype=np.float32)\n",
    "        self.item_feats = df[item_features].to_numpy(dtype=np.float32)\n",
    "\n",
    "        self.n_items = int(n_items)\n",
    "        self.user_pos = user_pos\n",
    "        self.neg_per_pos = int(neg_per_pos)\n",
    "        self.max_tries = int(max_tries)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def _sample_negatives(self, u, pos):\n",
    "        liked = self.user_pos.get(u, set())\n",
    "        if pos in liked:\n",
    "            pass\n",
    "\n",
    "        # Universe minus liked\n",
    "        if len(liked) < self.n_items - 1:\n",
    "            comp = np.setdiff1d(np.arange(self.n_items, dtype=np.int64),\n",
    "                                np.fromiter(liked, dtype=np.int64, count=len(liked)),\n",
    "                                assume_unique=False)\n",
    "            # Also exclude current positive just to be safe\n",
    "            comp = comp[comp != pos]\n",
    "            if comp.size >= self.neg_per_pos:\n",
    "                return np.random.choice(comp, size=self.neg_per_pos, replace=False).astype(np.int64)\n",
    "            # Fallback to allowing replacement if universe is tiny\n",
    "            return np.random.choice(comp, size=self.neg_per_pos, replace=True).astype(np.int64)\n",
    "\n",
    "        negs = []\n",
    "        tries = 0\n",
    "        while len(negs) < self.neg_per_pos and tries < self.max_tries:\n",
    "            j = np.random.randint(0, self.n_items, dtype=np.int64)\n",
    "            if j != pos and j not in liked:\n",
    "                negs.append(j)\n",
    "            tries += 1\n",
    "        # If still short, fill randomly from all except pos (may include collisions with liked if unavoidable)\n",
    "        if len(negs) < self.neg_per_pos:\n",
    "            pool = np.setdiff1d(np.arange(self.n_items, dtype=np.int64), np.array([pos], dtype=np.int64))\n",
    "            fill = np.random.choice(pool, size=self.neg_per_pos - len(negs), replace=True).astype(np.int64)\n",
    "            negs.extend(fill.tolist())\n",
    "        return np.array(negs, dtype=np.int64)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        u = self.users[idx]\n",
    "        pos = self.items[idx]\n",
    "        uf = self.user_feats[idx]\n",
    "        ifeat = self.item_feats[idx]\n",
    "\n",
    "        negs = self._sample_negatives(u, pos)\n",
    "\n",
    "        # Return tensors with desired dtypes; DataLoader will batch them\n",
    "        return (\n",
    "            torch.as_tensor(u, dtype=torch.long),\n",
    "            torch.as_tensor(pos, dtype=torch.long),\n",
    "            torch.as_tensor(negs, dtype=torch.long),\n",
    "            torch.from_numpy(uf),\n",
    "            torch.from_numpy(ifeat),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJxlsMeTEaP9"
   },
   "outputs": [],
   "source": [
    "class AdvancedNeuMF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, user_feat_dim, item_feat_dim,\n",
    "                 eg=32, em=32, layers=(128, 64, 32), use_bn=True):\n",
    "        super().__init__()\n",
    "        # Embeddings\n",
    "        self.user_gmf = nn.Embedding(n_users, eg)\n",
    "        self.item_gmf = nn.Embedding(n_items, eg)\n",
    "        self.user_mlp = nn.Embedding(n_users, em)\n",
    "        self.item_mlp = nn.Embedding(n_items, em)\n",
    "\n",
    "        # Project raw context\n",
    "        self.user_fc = nn.Linear(user_feat_dim, 16)\n",
    "        self.item_fc = nn.Linear(item_feat_dim, 16)\n",
    "\n",
    "        # MLP over [user_mlp, item_mlp, projected_user_ctx, projected_item_ctx]\n",
    "        dim = em*2 + 32\n",
    "        mlp = []\n",
    "        for h in layers:\n",
    "            mlp.append(nn.Linear(dim, h))\n",
    "            if use_bn: mlp.append(nn.BatchNorm1d(h))\n",
    "            mlp += [nn.ReLU(), nn.Dropout(0.2)]\n",
    "            dim = h\n",
    "        self.mlp = nn.Sequential(*mlp)\n",
    "\n",
    "        # Fusion of GMF and MLP tower\n",
    "        self.out = nn.Linear(eg + layers[-1], 1)\n",
    "\n",
    "        self._init()\n",
    "\n",
    "    def _init(self):\n",
    "        for emb in [self.user_gmf, self.item_gmf, self.user_mlp, self.item_mlp]:\n",
    "            nn.init.normal_(emb.weight, std=0.01)\n",
    "        nn.init.xavier_uniform_(self.user_fc.weight); nn.init.zeros_(self.user_fc.bias)\n",
    "        nn.init.xavier_uniform_(self.item_fc.weight); nn.init.zeros_(self.item_fc.bias)\n",
    "        nn.init.xavier_uniform_(self.out.weight);     nn.init.zeros_(self.out.bias)\n",
    "\n",
    "    def forward(self, u, i, uf, ifeat):\n",
    "\n",
    "        g = self.user_gmf(u) * self.item_gmf(i)  # (B, eg)\n",
    "\n",
    "        # project context, then concatenate into MLP stream\n",
    "        u_ctx = self.user_fc(uf)\n",
    "        i_ctx = self.item_fc(ifeat)\n",
    "\n",
    "        m_in = torch.cat([self.user_mlp(u), self.item_mlp(i), u_ctx, i_ctx], dim=-1)\n",
    "        m = self.mlp(m_in)\n",
    "\n",
    "        logits = self.out(torch.cat([g, m], dim=-1)).squeeze(-1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lXWk0lH6Ec2M"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def context_bce(model, users, pos_items, neg_items, u_feats, pos_i_feats, item_feat_matrix):\n",
    "\n",
    "    B, K = neg_items.shape\n",
    "\n",
    "\n",
    "    pos_logits = model(users, pos_items, u_feats, pos_i_feats)   # (B,)\n",
    "    pos_loss = F.binary_cross_entropy_with_logits(\n",
    "        pos_logits, torch.ones_like(pos_logits)\n",
    "    )\n",
    "\n",
    "\n",
    "    # replicate users & user features for K negatives\n",
    "    users_rep  = users.unsqueeze(1).expand(-1, K).reshape(-1)\n",
    "    u_feats_rep = u_feats.unsqueeze(1).expand(-1, K, -1).reshape(-1, u_feats.shape[1])\n",
    "\n",
    "    # flatten neg ids and lookup their own item features\n",
    "    n_flat = neg_items.reshape(-1)\n",
    "    neg_i_feats = item_feat_matrix[n_flat]\n",
    "\n",
    "    neg_logits = model(users_rep, n_flat, u_feats_rep, neg_i_feats).view(B, K)\n",
    "    neg_loss = F.binary_cross_entropy_with_logits(\n",
    "        neg_logits, torch.zeros_like(neg_logits)\n",
    "    )\n",
    "\n",
    "    return pos_loss + neg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_mGcHRIQogpu"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_with_context(model, test_df, user_pos, n_items, user_feat_df, item_feat_df, k=10, n_neg=99):\n",
    "    model.eval()\n",
    "    HR, NDCG = [], []\n",
    "\n",
    "    item_feat_mat = torch.tensor(item_feat_df[item_features].values, dtype=torch.float32, device=DEVICE)\n",
    "    user_feat_mat = torch.tensor(user_feat_df[user_features].values, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "    for u, pos in zip(test_df.u.values, test_df.i.values):\n",
    "        u = int(u); pos = int(pos)\n",
    "        s = user_pos[u]\n",
    "\n",
    "        negs = []\n",
    "        while len(negs) < n_neg:\n",
    "            j = np.random.randint(0, n_items)\n",
    "            if j != pos and j not in s:\n",
    "                negs.append(j)\n",
    "\n",
    "        items = np.array([pos] + negs, dtype=np.int64)\n",
    "        users = np.full_like(items, u)\n",
    "\n",
    "        uf = user_feat_mat[users]   # (1+n_neg, F_u)\n",
    "        ifeat = item_feat_mat[items]# (1+n_neg, F_i)\n",
    "\n",
    "        logits = model(\n",
    "            torch.tensor(users, device=DEVICE),\n",
    "            torch.tensor(items, device=DEVICE),\n",
    "            uf, ifeat\n",
    "        ).cpu().numpy()\n",
    "\n",
    "        rank = logits.argsort()[::-1]\n",
    "        topk = items[rank[:k]]\n",
    "\n",
    "        HR.append(1 if pos in topk else 0)\n",
    "        if pos in topk:\n",
    "            idx = np.where(topk == pos)[0][0]\n",
    "            NDCG.append(1 / np.log2(idx + 2))\n",
    "        else:\n",
    "            NDCG.append(0.0)\n",
    "\n",
    "    return float(np.mean(HR)), float(np.mean(NDCG))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "executionInfo": {
     "elapsed": 103,
     "status": "error",
     "timestamp": 1761282114603,
     "user": {
      "displayName": "Arshelle Raheja",
      "userId": "10851582231821550198"
     },
     "user_tz": -480
    },
    "id": "C5Lq0FYmEgP0",
    "outputId": "b77289c6-eddc-47ae-9a1d-93f512c48a20"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'item_feat_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1770531688.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Item feature matrix for negatives (DEVICE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m item_feat_matrix = torch.tensor(\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mitem_feat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'item_feat_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Loader\n",
    "train_loader = DataLoader(\n",
    "    ContextualImplicitDataset(train_df, n_items, user_pos, NEG_PER_POS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# Model\n",
    "model_adv = AdvancedNeuMF(\n",
    "    n_users, n_items, len(user_features), len(item_features),\n",
    "    eg=EMBED_GMF, em=EMBED_MLP, layers=MLP_LAYERS\n",
    ").to(DEVICE)\n",
    "\n",
    "opt = torch.optim.Adam(model_adv.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Item feature matrix for negatives (DEVICE)\n",
    "item_feat_matrix = torch.tensor(\n",
    "    item_feat_df[item_features].values, dtype=torch.float32, device=DEVICE\n",
    ")\n",
    "\n",
    "for e in range(1, EPOCHS + 1):\n",
    "    model_adv.train()\n",
    "    total = 0.0\n",
    "\n",
    "    for u, p, n, uf, ifeat_pos in train_loader:\n",
    "        u = u.to(DEVICE); p = p.to(DEVICE); n = n.to(DEVICE)\n",
    "        uf = uf.to(DEVICE); ifeat_pos = ifeat_pos.to(DEVICE)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss = context_bce(model_adv, u, p, n, uf, ifeat_pos, item_feat_matrix)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total += loss.item() * u.size(0)\n",
    "\n",
    "    hr, ndcg = evaluate_with_context(\n",
    "        model_adv, test_df, user_pos, n_items, user_feat_df, item_feat_df, k=TOPK\n",
    "    )\n",
    "\n",
    "    print(f\"Epoch {e:02d} | train_bce={total/len(train_df):.4f} | HR@{TOPK}={hr:.3f} | NDCG@{TOPK}={ndcg:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HkOGkJtcpNM5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1CBFnT8I8pzwRddj81rKNLNPAP9DkzXj_",
     "timestamp": 1762135697627
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
